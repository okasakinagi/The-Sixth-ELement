# AI 功能开发方案

本方案按照优先级，规划 AI 能力的目标、架构、接口、模型选择、成本、前后端交互与里程碑，作为研发与产品协作的基线文档。

## 目标与优先级

优先级从高到低：
1. 通过用户个人资料实现智能推荐和问卷匹配，LLM 理解问卷内容并推送给符合要求的用户
2. 智能问卷生成
3. 问卷数据分析与导出
4. 反作弊辅助
5. 质量控制

### 统一目标
- 提升问卷匹配效率与填写转化
- 降低发布门槛与提高问卷质量
- 为运营提供可量化的数据洞察
- 降低作弊与低质量内容的成本

## 系统现状与落点

现有后端为 Django（`core/`）+ MySQL，前端为 Vue3（`frontend/sixth_element/`）。

AI 功能主要落地模块：
- 后端：`core/` 新增 AI 服务层与 API 路由
- 前端：新增推荐/问卷生成/数据分析页面或模块
- 文档：补充 AI 接口与成本说明


## AI 交互页面设计（前端）

- 发布问卷页：右侧 AI 助手浮层
- 入口按钮：生成/优化/评分
- 支持“版本对比”和“一键应用”
- 问卷详情页：AI 总结与亮点（可选）
- 管理后台：AI 审核分数、风险提示、解释理由
- 个人中心：AI 使用记录与消耗提示
- 交互模式：非对话式 + 快速模板为主，必要时用对话

## 总体架构

### 服务分层
- **API 层**：`core/views.py` 新增 `/api/v1/ai/...` 路由
- **业务层**：`core/ai/services.py`（推荐、生成、分析、反作弊、质控）
- **模型层**：`core/ai/provider.py`（模型适配、路由、多模型切换）
- **数据层**：新增 `AiTask`、`AiUsage`、`AiRecommendation` 等模型

### 推荐与匹配流程（优先级 1）
1. 获取问卷内容、标签、目标条件
2. LLM 解析问卷意图并抽取“目标画像标签”
3. 用户画像与目标标签匹配（规则 + embedding 相似度）
4. 输出推荐队列与解释理由

### 技术选型建议
- LLM：支持中文、结构化输出（JSON）、稳定性高
- 向量检索：轻量方案可先用 DB 存储 embedding + 余弦相似度
- 缓存：Redis（可选，先用 DB 缓存）

## 功能详细方案

### 1) 智能推荐与问卷匹配

**目标**
- 让符合要求的用户更快看到相关问卷，提升匹配率与完成率。

**输入**
- 问卷内容（title/description/estimated_minutes/reward_points/标签）
- 用户画像（学校、领域、标签、历史填写行为）

**核心逻辑**
- LLM 结构化理解：将问卷解析为目标画像（年龄段、专业领域、兴趣标签、时长偏好）
- 规则过滤：先过滤明显不匹配用户（如时间冲突、重复填写）
- Embedding 相似度排序：对问卷与用户画像的文本进行 embedding，排序得分
- 结果输出：返回推荐用户列表与推荐解释

**后端接口（草案）**
- `POST /api/v1/ai/recommendations/surveys/{id}`
  - 返回：推荐用户列表、原因、匹配分
- `GET /api/v1/ai/recommendations/users/me`
  - 返回：推荐问卷列表与匹配理由

**数据模型（建议）**
- `AiRecommendation`: id, survey_id, user_id, score, reason, created_at
- `UserProfile`（可用现有 User 字段扩展）

**前端交互**
- 任务大厅：个性化推荐列表（标注“推荐理由”）
- 问卷发布页：提示“推荐覆盖人数”与预计转化

---

### 2) 智能问卷生成

**目标**
- 输入主题与目的，自动生成问卷结构与问题列表。

**接口草案**
- `POST /api/v1/ai/surveys/draft`
  - 输入：目的、受众、题型偏好、预计时长
  - 输出：标题、说明、问题列表（结构化 JSON）

**前端交互**
- 发布页新增“AI 生成”入口
- 生成结果支持编辑与版本对比

---

### 3) 问卷数据分析与导出

**目标**
- 自动总结问卷结果、提取要点、导出结构化报告。

**接口草案**
- `POST /api/v1/ai/surveys/{id}/analysis`
  - 输入：问卷填写记录
  - 输出：摘要、关键结论、分组分析建议

**前端交互**
- 问卷详情新增“AI 分析”区块
- 导出为 Markdown / PDF / CSV

---

### 4) 反作弊辅助

**目标**
- 为审核员提供风险提示，不直接做判定。

**接口草案**
- `POST /api/v1/ai/fills/anomaly-score`
  - 输入：填写记录、时长、历史行为
  - 输出：风险分 + 解释

**前端交互**
- 审核页面显示风险分、理由、标记

---

### 5) 质量控制

**目标**
- 在发布阶段检测低质量、违规或诱导性问卷。

**接口草案**
- `POST /api/v1/ai/surveys/quality-score`
  - 输出：质量评分、问题清单、修改建议

**前端交互**
- 发布页展示质量提示与优化建议

## 模型选择与路由策略

**候选模型（示例）**

- OpenAI GPT-4 系列

  优势：推理与工具调用强、英文/中文均衡
  适用：质量评估、复杂问卷改写
  成本：偏高（建议用于关键场景）

- Anthropic Claude 3 系列

  优势：长文本处理、对话稳定
  适用：长问卷润色与总结
  成本：中高

- Google Gemini 1.5 系列

  优势：长上下文、Google 生态
  适用：批量内容处理、摘要
  成本：中等

- Meta Llama 3 系列（开源）

  优势：可私有化部署
  适用：高并发低成本、需本地化
  成本：硬件成本为主

- 阿里 Qwen / 百度 ERNIE / 智谱 GLM / MiniMax / Moonshot

  优势：中文与国内合规
  适用：本地化应用、国内部署
  成本：中等，需看各家定价



**推荐策略**
- 轻量模型：负责推荐解析、初筛、摘要
- 强模型：负责质量控制、复杂生成、分析报告


## 成本估算（粗略）

单次调用成本：
- 推荐解析：输入 800 token + 输出 200 token
- 问卷生成：输入 600 token + 输出 1200 token
- 数据分析：输入 2000 token + 输出 600 token

建议以 `AiUsage` 表统计真实消耗，按用户/按天进行成本预算与限流。

## 数据与安全

- 对用户资料与问卷内容进行脱敏与最小化传输
- 设置请求频率限制与额度
- 日志记录：请求参数、模型版本、耗时、费用

## 里程碑规划

**M1：推荐 MVP（优先级 1）**
- LLM 解析问卷目标画像
- 推荐列表 API + 前端展示
- AiUsage 统计

**M2：问卷生成**
- 生成 API + 发布页集成
- 生成结果可编辑与版本对比

**M3：数据分析与导出**
- 分析 API + 导出功能

**M4：反作弊辅助**
- 风险评分 + 审核页提示

**M5：质量控制**
- 发布前质量评分 + 优化建议

## 风险与应对

- 推荐准确率低：引入规则过滤与 embedding 排序
- 成本不可控：分级模型 + 缓存 + 限流
- 体验不稳定：对失败场景提供降级策略

